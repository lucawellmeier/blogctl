import os
import shutil
import subprocess
import re
from datetime import datetime, timezone
from html.parser import HTMLParser

################################
## error handling and logging ##
################################

class BlogError(Exception):
    def __init__(self, message):
        self.message = message

###########################
## file system utilities ##
###########################

# creates a new directory if it not exists
def new_dir(dirname):
    os.makedirs(os.path.join(os.getcwd(), dirname), exist_ok=True)

# creates a new file but throws BlogError if it already exists
def new_file(filename, content):
    path = os.path.join(os.getcwd(), filename)
    if os.path.isfile(path):
        raise BlogError('file ' + path + ' already exists')
    with open(path, 'w') as f:
        f.write(content)

# removes all files and subdirectories in given directory ignoring dotfiles
def clear_dir(directory):
    for filename in os.listdir(directory):
        if filename.startswith('.'):
            continue
        path = os.path.join(directory, filename)
        if os.path.isfile(path) or os.path.islink(path):
            os.unlink(path)
        elif os.path.isdir(path):
            shutil.rmtree(path)

# moves all files and dirs from given directory to cwd
def flatten(directory):
    for filename in os.listdir(directory):
        path = os.path.join(directory, filename)
        if os.path.isfile(path) or os.path.islink(path):
            shutil.move(path, os.path.join(os.getcwd(), filename))
        elif os.path.isdir(path):
            shutil.move(path, os.getcwd())
    shutil.rmtree(directory)

#################
## git helpers ##
#################

# starts given git command. throws stderr through BlogError and returns stdout
def git(args):
    process = subprocess.Popen(['git'] + args, 
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    out, err = process.communicate()
    if 'fatal' in err.decode():
        raise BlogError('calling git command "' + ' '.join(args) + '":\n' + err.decode())
    return out.decode()

# extracts commit dates from a list of commits generated by 'git log'
def parse_commit_log(log):
    lines = log.splitlines(keepends=True)

    raw_commits = []
    for line in lines:
        if re.match('^commit', line):
            raw_commits.append([line])
        elif len(raw_commits) > 0:
            raw_commits[-1] += [line]
    
    commits = []
    for raw_commit in raw_commits:
        date_line = raw_commit[2] # line which contains the commit date
        date_string = re.match(r'^\s*Date:\s*(.+)\s*$', date_line).group(1)
        dt = datetime.strptime(date_string, '%c %z')
        commits.append(dt.astimezone(tz=timezone.utc))

    return sorted(commits)

# searches the commit history of a given file for publication date and last updates
def find_dates(article_file):
    add_commits = parse_commit_log(git(['log', '--diff-filter=A', '--', article_file]))
    if not add_commits:
        return []

    first_commit_date = add_commits[0]

    git(['checkout', 'master'])
    publications_after_commit = parse_commit_log(git(['log', '--since', '"' + first_commit_date.isoformat() + '"']))
    git(['checkout', 'dev'])

    if not publications_after_commit:
        return [] 

    all_changes = []
    all_changes.append(publications_after_commit[0])

    all_updates_log = git(['log', '--follow', '--after', '"' + all_changes[0].isoformat() + '"', '--', article_file])
    all_changes.extend(parse_commit_log(all_updates_log))
    return all_changes

#################
## html helper ##
#################

# finds the first headline and the first paragraph underneath
class HTMLTitleFinder(HTMLParser):
    def __init__(self, html):
        super().__init__()
        self.headline = ''
        self.first_paragraph = ''
        self._found_first_headline = False
        self._in_first_headline = False
        self._headline_tag = None
        self._found_first_paragraph = False
        self._in_first_paragraph = False
        self.feed(html)

    def handle_starttag(self, tag, attrs):
        if not self._found_first_headline:
            if re.match(r'h[123456]{1}', tag):
                self._found_first_headline = True
                self._in_first_headline = True
                self._headline_tag = tag
        elif self._found_first_headline and not self._in_first_headline and not self._found_first_paragraph:
            if tag == 'p':
                self._found_first_paragraph = True
                self._in_first_paragraph = True

    def handle_endtag(self, tag):
        if self._in_first_headline:
            if tag == self._headline_tag:
                self._in_first_headline = False
        elif self._in_first_paragraph:
            if tag == 'p':
                self._in_first_paragraph = False

    def handle_data(self, data):
        if self._in_first_headline:
            self.headline = data
        elif self._in_first_paragraph:
            self.first_paragraph = data
